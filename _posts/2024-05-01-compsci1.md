---
title: 'Operating Systems'
date: 2024-05-01
permalink: /posts/OS
tags:
  - computer science
  - operating systems
---

Let's look at operating systems in general, their purpose, and role.

Operating Systems
======
They dictate how software and applications can interact with the hardware. Some are minimilistic, some are complex. They are present to make sure the users and the developers don't worry about intricacies involved in how to make use of the hardware. They ensure you get accesses to resources you requested, if you have the right permissions. There are many programs to be run, but resources (like memory, CPU time, network requests) are limited. The OS gives an illusion that each program owns the entire resource it uses, for example, the entire CPU core, although the process might be switched out. The OS protect programs from each other. You wouldn't want one program to disrupt something happening in another program. OSes are supervisors. Since the OS is also a program, to distinguish between this and other programs, we have protection rings. Basically, it just indicates that programs (kernel) at ring 0 is the only one which can run privileged instructions and the programs at the outer rings aren't as privileged. What are privileged instructions? Well, something like updating virtual memory maps, context swtiches, I/O instructions. What this means is that any random program can't come along and remove a process from the running state, or can't change memory contents of another program and so on. There is a privilege bit in the CPU that is set when kernel code is being run, and unset when user code is being run. This bit is checked to see whether hardware resource access is allowed or not.

![image](/images/blog/protection_rings.png)

The point is that almost all OSes decides how things should be done with respect to how processes access resources. A good design should seperate mechanism and policies. Consider you want to eat in a restaurant (run a program). You simply look at the menu and order an item (launch the program). The chef (OS) prepares it for you (runs the program). What if you wanted the chef to grill the food a bit longer? What if you wanted the chef to heat it in the oven instead of the microvawe? What if you wanted them to make the entree before the appetizer? Well, you would specify these things before. Better yet, you could specify every detail on how you want your food prepared and served. This is what OSes are ideally supposed to do. Protection at the lowest possible layer, and exposing that interface. Flexibility in mechanisms at the user level for them to run their applications how they want. The user may be able to tailor mechanisms that are much faster for their applications. In the above analogy, if you know that the restaurant cooks food in the oven in batches every thirty minutes, and the batch is just about to start, you can request them to cook your entree (which requires the oven) first so that you don't need to wait for thirty minutes. And meanwhile they can work on your appetizer which doesn't require the oven. If this is so useful, then why don't modern OSes support this? Well, if you notice, you really need to know a lot of details if you want to tailor mechanisms for your application. And if you don't bother to, your application can possibly experience a terrible performance. This is one of the reasons why OSes implement their own mechanisms. 

![image](/images/blog/monolith_microkernel.svg.png)

Monolithic kernels (linux) are the ones that knit together all core functionalities like memory management, scheduling, device drivers, I/O and run in a privileged kernel-space. A crash of any service/driver in this kernel can crash the entire kernel. Then there is microkernels (windows is hybrid between monolithic and microkernel) which just provides basic services and isolates itself from device drivers and other services. It is more robust, smaller and hence easier to debug/manage. Finally comes the Unikernels (LibOS) which is ultra light weight OS implemented as a library that allows user programs to use hardware resources more efficiently. It is especially useful in virtualized environments where we run specialized applications like web servers. It lets the user program take control of the machine and directly access the hardware, and the OS logic (like implementation of TCP/IP) is moved into a library that can be used by different applications. Just like how you don't rewrite the "printf" function everytime you code and just use the standard library. LibOS also has the advantage of packaging libraries that are needed and not causing any bloat. 
